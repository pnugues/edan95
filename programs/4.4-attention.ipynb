{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa3ccdd9-ace9-4c89-ad8e-0faebeec5c20",
   "metadata": {
    "tags": []
   },
   "source": [
    "# The Attention mechanism and its implementation in Keras\n",
    "\n",
    "Computing self-attention of a sentence with GloVe embeddings and the `MultiHeadAttention` class in Keras\n",
    "\n",
    "Documents used to write the notebook:\n",
    "* Chollet's book, _Deep Learning with Python_, Second Edition, 2021, pp. 339-342\n",
    "* The Keras documentation: https://keras.io/api/layers/attention_layers/multi_head_attention/#multiheadattention-layer\n",
    "* Tensorflow documentation: https://www.tensorflow.org/api_docs/python/tf/keras/layers/MultiHeadAttention\n",
    "* Implementation: https://github.com/keras-team/keras/blob/v2.7.0/keras/layers/multi_head_attention.py\n",
    "\n",
    "Author: Pierre Nugues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba630853-00e0-4b64-ab86-01185c2deb0e",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d21c1d0-b06a-4340-bf3d-419a6edaf327",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg\n",
    "from scipy.special import softmax\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9119bcd1-e5af-4b3a-bd87-45276f71c7db",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Noncontextual embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5741d7ec-e588-4a6d-9cba-f8eae75f4fad",
   "metadata": {},
   "source": [
    "We load GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9d84fbb-b15e-45c0-bba8-6074ec0bb393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(file):\n",
    "    \"\"\"\n",
    "    Return the embeddings in the from of a dictionary\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    file = file\n",
    "    embeddings = {}\n",
    "    glove = open(file)\n",
    "    for line in glove:\n",
    "        values = line.strip().split()\n",
    "        word = values[0]\n",
    "        vector = np.array(values[1:], dtype='float32')\n",
    "        embeddings[word] = vector\n",
    "    glove.close()\n",
    "    embeddings_dict = embeddings\n",
    "    embedded_words = sorted(list(embeddings_dict.keys()))\n",
    "    return embeddings_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14e0a3c6-6e89-4500-b555-fb40efb5bcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_file = '/Users/pierre/Documents/Cours/EDAN20/corpus/glove.6B.50d.txt'\n",
    "embeddings_dict = load(embedding_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6ba6dc1-a704-4e08-b89b-fc5325ebcf14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.5213  ,  0.10522 ,  0.38162 , -0.50801 ,  0.032423, -0.13484 ,\n",
       "       -1.2474  ,  0.79813 ,  0.84691 , -1.101   ,  0.88743 ,  1.3749  ,\n",
       "        0.42928 ,  0.65717 , -0.2636  , -0.41759 , -0.48846 ,  0.91061 ,\n",
       "       -1.7158  , -0.438   ,  0.78395 ,  0.19636 , -0.40657 , -0.53971 ,\n",
       "        0.82442 , -1.7434  ,  0.14285 ,  0.28037 ,  1.1688  ,  0.16897 ,\n",
       "        2.2271  , -0.58273 , -0.45723 ,  0.62814 ,  0.54441 ,  0.28462 ,\n",
       "        0.44485 , -0.55343 , -0.36493 , -0.016425,  0.40876 , -0.87148 ,\n",
       "        1.5513  , -0.80704 , -0.10036 , -0.28461 , -0.33216 , -0.50609 ,\n",
       "        0.48272 , -0.66198 ], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dict['ship']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b9f1dd-07e7-4995-abea-8c2fe202e16e",
   "metadata": {},
   "source": [
    "## Cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c648e3-c5f9-4e70-82f3-1b138400c1af",
   "metadata": {},
   "source": [
    "Let us compute the cosine similarity of the words in a sentence:\n",
    "> I must go back to my ship and to my crew\n",
    "\n",
    "_Odyssey_, book I \n",
    "\n",
    "Remeber that:\n",
    "$$\\cos(\\mathbf{u}, \\mathbf{v}) = \\frac{\\mathbf{u} \\cdot \\mathbf{v}}{||\\mathbf{u}|| \\cdot ||\\mathbf{v} ||}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02456cd9-bc86-4ccb-ad68-e4124cb16e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'I must go back to my ship and to my crew'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0851862-27f2-4fd9-98ed-e9aa64d2dcd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'must', 'go', 'back', 'to', 'my', 'ship', 'and', 'to', 'my', 'crew']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = sentence.lower().split()\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600768d3-408b-48cc-994d-710fdb0c45df",
   "metadata": {},
   "source": [
    "We build the embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef726a70-39fb-4bc9-826b-fa4efa6f889e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_seq = []\n",
    "for word in words:\n",
    "    embeddings_seq += [embeddings_dict[word]]\n",
    "embeddings_seq = np.array(embeddings_seq)\n",
    "#embeddings_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9049e121-9f7b-4392-a4db-e99e06f25bf4",
   "metadata": {},
   "source": [
    "We compute the attention scores as the pairwise cosines of the word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11d368f1-caf4-4ad9-a7bb-e00d35e0e926",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_scores_cos = np.zeros((len(words),len(words)))\n",
    "for i in range(len(words)):\n",
    "    scores = np.zeros(len(words))\n",
    "    for j in range(len(words)):\n",
    "        scores[j] = (np.dot(embeddings_seq[i], embeddings_seq[j])/\n",
    "                     (np.linalg.norm(embeddings_seq[i]) * \n",
    "                      np.linalg.norm(embeddings_seq[j])))\n",
    "        #scores[j] = np.dot(embeddings_dict[words[i]], embeddings_dict[words[j]])\n",
    "    attn_scores_cos[i] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6db4f3c-57c0-4e4d-a66e-5ecb94cf5697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ti\tmust\tgo\tback\tto\tmy\tship\tand\tto\tmy\tcrew\t\n",
      "i\t1.00\t0.75\t0.86\t0.76\t0.73\t0.90\t0.35\t0.65\t0.73\t0.90\t0.42\t\n",
      "must\t0.75\t1.00\t0.85\t0.68\t0.87\t0.69\t0.42\t0.69\t0.87\t0.69\t0.45\t\n",
      "go\t0.86\t0.85\t1.00\t0.84\t0.84\t0.81\t0.41\t0.68\t0.84\t0.81\t0.49\t\n",
      "back\t0.76\t0.68\t0.84\t1.00\t0.83\t0.76\t0.49\t0.77\t0.83\t0.76\t0.51\t\n",
      "to\t0.73\t0.87\t0.84\t0.83\t1.00\t0.68\t0.54\t0.86\t1.00\t0.68\t0.51\t\n",
      "my\t0.90\t0.69\t0.81\t0.76\t0.68\t1.00\t0.38\t0.63\t0.68\t1.00\t0.44\t\n",
      "ship\t0.35\t0.42\t0.41\t0.49\t0.54\t0.38\t1.00\t0.46\t0.54\t0.38\t0.78\t\n",
      "and\t0.65\t0.69\t0.68\t0.77\t0.86\t0.63\t0.46\t1.00\t0.86\t0.63\t0.49\t\n",
      "to\t0.73\t0.87\t0.84\t0.83\t1.00\t0.68\t0.54\t0.86\t1.00\t0.68\t0.51\t\n",
      "my\t0.90\t0.69\t0.81\t0.76\t0.68\t1.00\t0.38\t0.63\t0.68\t1.00\t0.44\t\n",
      "crew\t0.42\t0.45\t0.49\t0.51\t0.51\t0.44\t0.78\t0.49\t0.51\t0.44\t1.00\t\n"
     ]
    }
   ],
   "source": [
    "print('\\t', end='')\n",
    "for i in range(len(words)):\n",
    "    print(words[i], end='\\t')\n",
    "print()\n",
    "\n",
    "for i in range(attn_scores_cos.shape[0]):\n",
    "    print(words[i], end='\\t')\n",
    "    for j in range(attn_scores_cos.shape[1]):\n",
    "        print(f\"{attn_scores_cos[i,j]:.2f}\", end='\\t')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591c498b-1650-403a-9ba1-780ba3ef4dd5",
   "metadata": {},
   "source": [
    "## Contextual embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958548e0-5560-4c09-bb13-9731cccf72fa",
   "metadata": {},
   "source": [
    "We design a new vector representation for _ship_ so that it receives an influence from _crew_ and the other words of its context. This influence will depend on the embeddings from te context. Let us use the cosine similarities as attention scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8581ba59-875c-490b-b419-eece41e99960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.34663907, 0.41782767, 0.40681112, 0.48531651, 0.54014385,\n",
       "       0.3791028 , 1.        , 0.45863339, 0.54014385, 0.3791028 ,\n",
       "       0.78480232])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_scores_cos[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca41244-cf33-4d0c-9bd9-d1b705f45b1f",
   "metadata": {},
   "source": [
    "We compute the new embeddings as the sum of the noncontextual embeddings weighted by the cosine similarity. We have contextual embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a2700f2-3bbe-4911-9e73-bc32ad1cf082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.2289004 ,   0.6421813 ,   1.4712307 ,  -2.3537598 ,\n",
       "         2.24136   ,  -0.42374972,  -4.105233  ,   2.6215937 ,\n",
       "         0.17187847,  -2.4323788 ,   1.3882339 ,   3.7241364 ,\n",
       "        -1.9721073 ,   1.1893367 ,   2.2511206 ,   0.9501926 ,\n",
       "        -0.76461965,   1.0288985 ,  -3.0553396 ,  -3.6306143 ,\n",
       "         0.8304751 ,   2.9298651 ,   1.3221488 ,  -0.70915157,\n",
       "         2.9745216 , -10.595905  ,  -1.3167882 ,   0.20589754,\n",
       "         3.5456927 ,  -2.7711318 ,  18.2672    ,   2.4816926 ,\n",
       "        -3.588689  ,   0.32967418,   1.2717707 ,   0.653944  ,\n",
       "         1.5873263 ,   0.01946718,   0.7724056 ,  -1.4620132 ,\n",
       "        -0.2066631 ,  -1.2463707 ,   2.1504393 ,  -0.18107067,\n",
       "        -0.5025929 ,  -0.2888131 ,  -0.5059958 ,  -1.9675692 ,\n",
       "        -0.06049497,  -0.6725442 ], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_embeddings_ship = (0.35 * embeddings_dict['i'] + \n",
    "                  0.42 * embeddings_dict['must'] + \n",
    "                  0.41 * embeddings_dict['go'] +\n",
    "                  0.49 * embeddings_dict['back'] +\n",
    "                  0.54 * embeddings_dict['to'] + \n",
    "                  0.38 * embeddings_dict['my'] +\n",
    "                  1.00 * embeddings_dict['ship'] +\n",
    "                  0.46 * embeddings_dict['and'] +\n",
    "                  0.54 * embeddings_dict['to'] +\n",
    "                  0.38 * embeddings_dict['my'] +\n",
    "                  0.78 * embeddings_dict['crew'])\n",
    "new_embeddings_ship"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135c0613-cac0-4fbc-abc0-30f0727a79a1",
   "metadata": {},
   "source": [
    "Exact computation with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc382295-000e-469a-b855-00580d42750c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.23191333e+00,  6.40820291e-01,  1.47175971e+00, -2.34335986e+00,\n",
       "        2.23580736e+00, -4.18774560e-01, -4.10024511e+00,  2.62113565e+00,\n",
       "        1.80098590e-01, -2.43597248e+00,  1.39229628e+00,  3.71878745e+00,\n",
       "       -1.96033551e+00,  1.19803266e+00,  2.23935332e+00,  9.37625410e-01,\n",
       "       -7.70491710e-01,  1.03488285e+00, -3.06148983e+00, -3.62586930e+00,\n",
       "        8.34011570e-01,  2.92812823e+00,  1.31648467e+00, -7.13029835e-01,\n",
       "        2.96666448e+00, -1.05669432e+01, -1.30994248e+00,  2.02828896e-01,\n",
       "        3.53620975e+00, -2.75710038e+00,  1.82203369e+01,  2.46983156e+00,\n",
       "       -3.58043840e+00,  3.26042563e-01,  1.27600905e+00,  6.57010953e-01,\n",
       "        1.58887761e+00,  1.15708439e-02,  7.66195274e-01, -1.45595292e+00,\n",
       "       -2.03622785e-01, -1.24835755e+00,  2.15496249e+00, -1.87666416e-01,\n",
       "       -5.02529457e-01, -2.91283600e-01, -5.10062909e-01, -1.95960099e+00,\n",
       "       -5.88529337e-02, -6.73801397e-01])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(attn_scores_cos @ embeddings_seq)[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f8b7cf-0ef8-46dd-96d2-e94601dcdf45",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Self-attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe38dcb-887e-4b92-871e-011918b76140",
   "metadata": {},
   "source": [
    "Vaswani et al. (2017) defined attention as:\n",
    "$$\n",
    "\\text{Attention}(\\mathbf{Q}, \\mathbf{K}, \\mathbf{Q}) = \\text{softmax}(\\frac{\\mathbf{Q}  \\mathbf{K}^\\intercal}{\\sqrt{d_k}})  \\mathbf{V},\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\begin{array}{lcl}\n",
    "\\mathbf{Q} &=& \\mathbf{X} \\mathbf{W}_Q,   \\\\\n",
    "\\mathbf{K} &=& \\mathbf{X} \\mathbf{W}_K , \\\\\n",
    "\\mathbf{V} &=& \\mathbf{X} \\mathbf{W}_V.\\\\\n",
    "\\end{array}\n",
    "$$\n",
    "and $\\mathbf{X}$ represents complete input sequence (all the tokens).\n",
    "\n",
    "$d_k$ is the dimension of the input and $\\sqrt{d_k}$Â a scaling factor. The $\\text{softmax}$ function is defined as:\n",
    "$$\n",
    "\\text{softmax}(x_1, x_2, ..., x_j, ..., x_n) = (\\frac{e^{x_1}}{\\sum_{i=1}^n e^{x_i}}, \\frac{e^{x_2}}{\\sum_{i=1}^n e^{x_i}}, ..., \\frac{e^{x_j}}{\\sum_{i=1}^n e^{x_i}}, ..., \\frac{e^{x_n}}{\\sum_{i=1}^n e^{x_i}})\n",
    "$$\n",
    "\n",
    "We omit the weight matrices and we use the same embeddings for $\\mathbf{Q}$, $\\mathbf{K}$, and $\\mathbf{Q}$: GloVe embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bac5b7-2636-405a-ad9d-5ce0aec3f541",
   "metadata": {},
   "source": [
    "For the matrix above, self attention, $\\text{softmax}(\\frac{\\mathbf{Q}  \\mathbf{K}^\\intercal}{\\sqrt{d_k}})$,  for _ship_ yields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd81a119-112f-4eb1-9f36-7fa0514ac14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_scores = softmax((embeddings_seq @ embeddings_seq.T)/\n",
    "                      np.sqrt(embeddings_dict['i'].shape), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9658c8f-2804-4f0b-8c6d-c0cd5e10e0c2",
   "metadata": {},
   "source": [
    "The scaled and normalized attention scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf831af2-f40f-4512-a661-e300c467b897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ti\tmust\tgo\tback\tto\tmy\tship\tand\tto\tmy\tcrew\t\n",
      "i\t0.36\t0.05\t0.07\t0.05\t0.04\t0.19\t0.01\t0.02\t0.04\t0.19\t0.01\t\n",
      "must\t0.14\t0.20\t0.10\t0.06\t0.11\t0.10\t0.03\t0.05\t0.11\t0.10\t0.02\t\n",
      "go\t0.18\t0.09\t0.14\t0.09\t0.08\t0.13\t0.02\t0.04\t0.08\t0.13\t0.02\t\n",
      "back\t0.14\t0.05\t0.09\t0.19\t0.08\t0.12\t0.03\t0.06\t0.08\t0.12\t0.03\t\n",
      "to\t0.11\t0.11\t0.09\t0.09\t0.15\t0.08\t0.04\t0.07\t0.15\t0.08\t0.03\t\n",
      "my\t0.19\t0.03\t0.05\t0.04\t0.03\t0.29\t0.01\t0.02\t0.03\t0.29\t0.01\t\n",
      "ship\t0.03\t0.03\t0.03\t0.04\t0.05\t0.03\t0.55\t0.03\t0.05\t0.03\t0.13\t\n",
      "and\t0.10\t0.08\t0.07\t0.10\t0.12\t0.09\t0.04\t0.15\t0.12\t0.09\t0.04\t\n",
      "to\t0.11\t0.11\t0.09\t0.09\t0.15\t0.08\t0.04\t0.07\t0.15\t0.08\t0.03\t\n",
      "my\t0.19\t0.03\t0.05\t0.04\t0.03\t0.29\t0.01\t0.02\t0.03\t0.29\t0.01\t\n",
      "crew\t0.06\t0.05\t0.05\t0.06\t0.05\t0.06\t0.21\t0.04\t0.05\t0.06\t0.31\t\n"
     ]
    }
   ],
   "source": [
    "print('\\t', end='')\n",
    "for i in range(len(words)):\n",
    "    print(words[i], end='\\t')\n",
    "print()\n",
    "for i in range(attn_scores.shape[0]):\n",
    "    print(words[i], end='\\t')\n",
    "    for j in range(attn_scores.shape[1]):\n",
    "        print(f\"{attn_scores[i,j]:.2f}\", end='\\t')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7894ff99-35da-460d-8121-b69492a26e21",
   "metadata": {},
   "source": [
    "For _ship:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e556eebb-36bd-4046-90a2-bdc0df48523b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03030739, 0.03024587, 0.02764812, 0.0406623 , 0.04593486,\n",
       "       0.03426556, 0.55297636, 0.02968701, 0.04593486, 0.03426556,\n",
       "       0.12807212])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_scores[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecb44a4-ba75-400e-96da-da4f197b51c8",
   "metadata": {},
   "source": [
    "We have the weights of 55% for _ship_ and 13% for _crew_, the rest from the other words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5624ca6b-c824-4e1c-a23e-2e05222d3d26",
   "metadata": {},
   "source": [
    "And the new contextual embedding is for _ship_ is a linear combination:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb9d28fa-a98a-4579-9ff6-4ceba203dcb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.044195  ,  0.09659944,  0.34672633, -0.42381316,  0.22031876,\n",
       "       -0.09556399, -0.9915037 ,  0.6637363 ,  0.436829  , -0.794322  ,\n",
       "        0.5639492 ,  0.98379046,  0.02403222,  0.5065729 ,  0.07323891,\n",
       "       -0.17404956, -0.3321709 ,  0.561386  , -1.1613255 , -0.5717251 ,\n",
       "        0.43559432,  0.41197652, -0.06589289, -0.33361682,  0.6578553 ,\n",
       "       -1.7420686 , -0.03438139,  0.14395224,  0.8546864 , -0.14299722,\n",
       "        2.6613998 , -0.05529932, -0.537614  ,  0.3057363 ,  0.40678102,\n",
       "        0.22314468,  0.39586747, -0.29400417, -0.11625631, -0.13404053,\n",
       "        0.17093891, -0.533202  ,  0.9551976 , -0.41781372, -0.10581654,\n",
       "       -0.17152235, -0.22509809, -0.39232036,  0.20977767, -0.3625378 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_attention_ship = (0.03 * embeddings_dict['i'] + \n",
    "                  0.03 * embeddings_dict['must'] + \n",
    "                  0.03 * embeddings_dict['go'] +\n",
    "                  0.04 * embeddings_dict['back'] +\n",
    "                  0.05 * embeddings_dict['to'] + \n",
    "                  0.03 * embeddings_dict['my'] +\n",
    "                  0.55 * embeddings_dict['ship'] +\n",
    "                  0.03 * embeddings_dict['and'] +\n",
    "                  0.05 * embeddings_dict['to'] +\n",
    "                  0.03 * embeddings_dict['my'] +\n",
    "                  0.13 * embeddings_dict['crew'])\n",
    "self_attention_ship"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc714db7-aa8d-41de-b844-0e2299ae829d",
   "metadata": {},
   "source": [
    "Exact and complete computation of the whole matrix with numpy of $\\text{softmax}(\\frac{\\mathbf{Q}  \\mathbf{K}^\\intercal}{\\sqrt{d_k}})  \\mathbf{V}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ea8976f-3ee2-406d-9318-2ca0eecb5616",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "self_attention = attn_scores @ embeddings_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afaa573-f2bd-49d2-9cb5-dced32b4c5a3",
   "metadata": {},
   "source": [
    "For _ship:_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "069655f9-bd3a-4b04-903a-c65ae881baec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.0387307 ,  0.10328993,  0.34260821, -0.43199392,  0.2236531 ,\n",
       "       -0.09583739, -0.99261578,  0.66616271,  0.4423922 , -0.7941921 ,\n",
       "        0.56381569,  0.99210325,  0.02053569,  0.50824176,  0.07430461,\n",
       "       -0.17727756, -0.34077056,  0.56745014, -1.15453678, -0.57175906,\n",
       "        0.42881261,  0.41905235, -0.06575875, -0.33385476,  0.66821521,\n",
       "       -1.74733617, -0.04854005,  0.15311078,  0.86423044, -0.14474712,\n",
       "        2.65712497, -0.05447188, -0.53432358,  0.31597919,  0.40407802,\n",
       "        0.22768488,  0.39576729, -0.29159369, -0.11262517, -0.13846768,\n",
       "        0.1743577 , -0.53750545,  0.94985317, -0.41448157, -0.10386168,\n",
       "       -0.17551405, -0.22132868, -0.39945137,  0.21188122, -0.36097601])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_attention[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e785968-a8ee-43ae-a1a5-da1217468e0c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Chollet's implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6319f1f1-ea0b-49d4-b2e8-692b17fc99ba",
   "metadata": {},
   "source": [
    "Now we follow Chollet's book (2021), page 339, to outline the computation. The function below is drawn his the book, page 339, and is slightly modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87610174-3f24-4c13-950f-17238a09aafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_attention(input_sequence):\n",
    "    output = np.zeros(shape=input_sequence.shape) \n",
    "    attn_scores = []\n",
    "    # The output will consist of contextual embeddinsgs of the same shape\n",
    "    for i, pivot_vector in enumerate(input_sequence):\n",
    "        scores = np.zeros(shape=(len(input_sequence),)) \n",
    "        for j, vector in enumerate(input_sequence):\n",
    "            scores[j] = np.dot(pivot_vector, vector.T) # Q K^T\n",
    "        scores /= np.sqrt(input_sequence.shape[1]) # sqrt(d_k)\n",
    "        scores = softmax(scores) # softmax(Q K^T / sqrt(d_k))\n",
    "        attn_scores += [scores]\n",
    "        new_pivot_representation = np.zeros(shape=pivot_vector.shape) \n",
    "        for j, vector in enumerate(input_sequence):\n",
    "             new_pivot_representation += vector * scores[j]\n",
    "        output[i] = new_pivot_representation\n",
    "    return output, np.array(attn_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e413784-1564-4b99-bcab-d124cad45d73",
   "metadata": {},
   "source": [
    "As input sequence, we use the GloVe embeddings of the words again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0b5f11c-b986-48a8-9469-5b4f6e9515f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'must', 'go', 'back', 'to', 'my', 'ship', 'and', 'to', 'my', 'crew']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9241a91-51cd-4a2a-888a-d22ff8b43599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.5213  ,  0.10522 ,  0.38162 , -0.50801 ,  0.032423, -0.13484 ,\n",
       "       -1.2474  ,  0.79813 ,  0.84691 , -1.101   ,  0.88743 ,  1.3749  ,\n",
       "        0.42928 ,  0.65717 , -0.2636  , -0.41759 , -0.48846 ,  0.91061 ,\n",
       "       -1.7158  , -0.438   ,  0.78395 ,  0.19636 , -0.40657 , -0.53971 ,\n",
       "        0.82442 , -1.7434  ,  0.14285 ,  0.28037 ,  1.1688  ,  0.16897 ,\n",
       "        2.2271  , -0.58273 , -0.45723 ,  0.62814 ,  0.54441 ,  0.28462 ,\n",
       "        0.44485 , -0.55343 , -0.36493 , -0.016425,  0.40876 , -0.87148 ,\n",
       "        1.5513  , -0.80704 , -0.10036 , -0.28461 , -0.33216 , -0.50609 ,\n",
       "        0.48272 , -0.66198 ], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dict['ship']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a933701c-4563-431b-adcf-824630ab09db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 50)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_seq.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc31a35a-9a3c-4f8f-b03e-c87846cbaa7f",
   "metadata": {},
   "source": [
    "We compute the new embeddings and the attentions scores. The result is a pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2208cbaa-bfdf-443d-a234-58d711d62474",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_output = self_attention(embeddings_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1afda43d-64aa-4d4e-afb8-a81e1b79c62a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, (11, 50), (11, 11))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(attn_output), \n",
    " attn_output[0].shape, \n",
    " attn_output[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756b5b47-c11a-4e5b-9f5a-571fa301980c",
   "metadata": {},
   "source": [
    "Attention scores for _ship_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb6db6fc-e644-4982-a1dd-43e00188b535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0303074 , 0.03024588, 0.02764812, 0.04066233, 0.04593488,\n",
       "       0.03426557, 0.55297623, 0.02968703, 0.04593488, 0.03426557,\n",
       "       0.12807209])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_output[1][6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77981b51-abd6-4866-b3a0-ca35df7b8474",
   "metadata": {},
   "source": [
    "The new contextual embeddings for _ship:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d67ab25-cafc-41dd-839d-99a51c4d51b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.03873055,  0.10328993,  0.34260817, -0.43199395,  0.22365316,\n",
       "       -0.09583739, -0.99261573,  0.66616262,  0.44239205, -0.79419196,\n",
       "        0.56381559,  0.99210317,  0.02053557,  0.50824163,  0.07430472,\n",
       "       -0.17727741, -0.3407705 ,  0.56744999, -1.1545366 , -0.57175908,\n",
       "        0.42881253,  0.41905238, -0.06575866, -0.33385471,  0.66821517,\n",
       "       -1.74733627, -0.0485401 ,  0.15311076,  0.86423036, -0.14474725,\n",
       "        2.65712533, -0.05447172, -0.53432362,  0.31597912,  0.40407797,\n",
       "        0.22768482,  0.39576725, -0.29159359, -0.11262507, -0.13846773,\n",
       "        0.17435764, -0.53750533,  0.94985298, -0.41448147, -0.10386168,\n",
       "       -0.17551402, -0.22132863, -0.39945136,  0.21188116, -0.36097596])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_output[0][6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dd9e67-74f1-4188-b5cc-8fee780a2a1d",
   "metadata": {},
   "source": [
    "## Keras implementation\n",
    " \n",
    "Keras has an implementation of self-attention encapsulated in the `MultiHeadAttention` class. Before going to the attention module, the query, key value, goes through a dense layer. The output also goes through a dense layer (missing from Chollet's book, page 342). These three layers are initialized with Glorot's algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "69c3124e-0197-4713-a837-c880734509bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import MultiHeadAttention\n",
    "\n",
    "att_layer = MultiHeadAttention(num_heads=1, \n",
    "                               key_dim=50, \n",
    "                               #kernel_initializer=tf.keras.initializers.ones(),\n",
    "                               use_bias=False, \n",
    "                               attention_axes=(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e550c7e-5039-4ca5-8cd2-fab2dd66ddab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 11, 50)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([embeddings_seq]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "396c1d82-c5a2-4fee-be93-54229835eea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-22 20:18:59.923568: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "(attn_output, attn_scores) = att_layer(np.array([embeddings_seq]), \n",
    "          np.array([embeddings_seq]),\n",
    "          np.array([embeddings_seq]),\n",
    "         return_attention_scores=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c42892-b9cb-4e06-a63f-b1b9f79506db",
   "metadata": {},
   "source": [
    "The attention score for _ship:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a6164627-82f0-4f9d-8c55-e48d05a6f155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(11,), dtype=float32, numpy=\n",
       "array([0.09334587, 0.09094715, 0.09149163, 0.09054147, 0.09002435,\n",
       "       0.09244619, 0.08981434, 0.08916097, 0.09002435, 0.09244619,\n",
       "       0.08975761], dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_scores[0][0][6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c724425-8380-4eb3-8610-a8942e0cad6a",
   "metadata": {},
   "source": [
    "### The initial dense layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223bbf4b-0deb-4337-843a-d5a35452fed4",
   "metadata": {},
   "source": [
    "The weight initial values with the 4 matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3a77c5f-7ad6-4826-b5b1-c314e31fa45b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_init = att_layer.weights\n",
    "len(w_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "36e537a9-dc43-48e4-ae18-9ca02c8d500a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'multi_head_attention/query/kernel:0' shape=(50, 1, 50) dtype=float32, numpy=\n",
       " array([[[ 0.0235358 , -0.04158013,  0.02329776, ...,  0.03353316,\n",
       "          -0.04693759, -0.01708426]],\n",
       " \n",
       "        [[ 0.04184161,  0.02855625, -0.04137975, ...,  0.0118022 ,\n",
       "           0.01659506, -0.03278984]],\n",
       " \n",
       "        [[ 0.02323494,  0.02261272,  0.01935604, ..., -0.04029571,\n",
       "           0.04366339,  0.01383097]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.03462507,  0.00065291, -0.01841628, ..., -0.00940876,\n",
       "          -0.04844818, -0.02721525]],\n",
       " \n",
       "        [[ 0.01191358,  0.00262818,  0.03573297, ...,  0.02754027,\n",
       "           0.00291654, -0.03835024]],\n",
       " \n",
       "        [[ 0.01706018, -0.00571505, -0.03109601, ...,  0.04206156,\n",
       "          -0.01439562, -0.01343737]]], dtype=float32)>,\n",
       " <tf.Variable 'multi_head_attention/key/kernel:0' shape=(50, 1, 50) dtype=float32, numpy=\n",
       " array([[[ 1.3113622e-02, -3.7193641e-02, -3.1759270e-02, ...,\n",
       "           1.3093915e-02, -4.5989122e-02, -2.1870652e-02]],\n",
       " \n",
       "        [[ 4.4183061e-04,  9.9529997e-03,  2.6203394e-03, ...,\n",
       "          -4.3006938e-02, -1.9707523e-02,  4.5224778e-02]],\n",
       " \n",
       "        [[-3.7550408e-02, -2.0744788e-02, -1.7670440e-02, ...,\n",
       "           3.7513219e-02,  1.7157681e-02,  3.7695549e-02]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 1.8070705e-02, -3.3765566e-02, -4.3779768e-02, ...,\n",
       "          -4.0510748e-02,  4.3870553e-02,  6.0774758e-03]],\n",
       " \n",
       "        [[ 4.4643879e-02,  1.8510595e-02,  1.2293942e-02, ...,\n",
       "           1.1707872e-02, -2.7580582e-02, -3.8883749e-02]],\n",
       " \n",
       "        [[-3.0618591e-02,  2.3074046e-02,  3.3778511e-02, ...,\n",
       "          -5.7835132e-05,  2.5192954e-02,  2.8636590e-02]]], dtype=float32)>,\n",
       " <tf.Variable 'multi_head_attention/value/kernel:0' shape=(50, 1, 50) dtype=float32, numpy=\n",
       " array([[[-3.5498895e-02,  1.4712647e-02, -4.2020719e-02, ...,\n",
       "          -4.1714687e-02,  6.7392141e-03, -1.6704392e-02]],\n",
       " \n",
       "        [[-1.5089747e-02, -2.0849960e-02,  2.6008785e-02, ...,\n",
       "           2.3246251e-02, -3.5253275e-02, -4.0980130e-03]],\n",
       " \n",
       "        [[ 6.8022795e-03,  2.5963254e-02, -6.4033307e-03, ...,\n",
       "           1.6231619e-02, -2.8866610e-02, -4.5686156e-02]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 1.1164054e-02,  1.3982248e-02,  1.9772403e-02, ...,\n",
       "           3.0794889e-02, -5.2874014e-03,  1.2083888e-02]],\n",
       " \n",
       "        [[-1.6478989e-02,  1.1090707e-02, -1.8578224e-02, ...,\n",
       "          -4.2408705e-05, -1.5254870e-02, -3.6611203e-02]],\n",
       " \n",
       "        [[ 3.7989080e-02,  1.8754490e-03, -4.3518584e-02, ...,\n",
       "          -3.3093039e-02,  4.2610176e-02,  3.1499140e-02]]], dtype=float32)>,\n",
       " <tf.Variable 'multi_head_attention/attention_output/kernel:0' shape=(1, 50, 50) dtype=float32, numpy=\n",
       " array([[[ 0.1572225 , -0.19879726,  0.11295767, ..., -0.03307068,\n",
       "          -0.21106955, -0.11857906],\n",
       "         [ 0.130888  ,  0.21839495,  0.1120051 , ..., -0.1424785 ,\n",
       "          -0.19705336, -0.05323201],\n",
       "         [-0.22324762,  0.12479298,  0.21759398, ..., -0.21401007,\n",
       "          -0.05592397, -0.11858654],\n",
       "         ...,\n",
       "         [-0.16343564, -0.10100235,  0.1751198 , ..., -0.04511027,\n",
       "           0.00430825, -0.17177422],\n",
       "         [-0.03823256, -0.15056396,  0.09115301, ..., -0.14653328,\n",
       "           0.21098132,  0.23344426],\n",
       "         [ 0.20105518,  0.13265051, -0.15436366, ...,  0.231429  ,\n",
       "          -0.01064183,  0.0495619 ]]], dtype=float32)>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c93855c-6d96-4612-8ba4-2b313a8e1174",
   "metadata": {},
   "source": [
    "### By-passing the dense layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a924d7c1-f322-4772-9f5b-fd6430954651",
   "metadata": {},
   "source": [
    "We create identity matrices to pass through the dense layers and recover the attention values and scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6afc443-2e3b-4e27-b2de-7b388b7b790d",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_50 = np.identity(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d138eabb-884d-4afb-9a7e-fc5131a65285",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_pt_50 = [i_50.reshape(50, 1, 50) for _ in range(3)] + [i_50.reshape(1, 50, 50)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16b614e-34ad-4a49-bd74-ce48c57e7ca6",
   "metadata": {},
   "source": [
    "We set the new weights (pass through)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af4fa87e-9e8c-4216-be9e-3a93cccddbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "att_layer.set_weights(w_pt_50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f34906-38db-488d-b127-c76fc070e7b1",
   "metadata": {},
   "source": [
    "### Multihead attention without the dense layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b083c3-77b0-4115-a3aa-7041a9f8be15",
   "metadata": {},
   "source": [
    "We obtain now the same results as the `self_attention()` function for _ship:_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de86e9c-c982-4eb0-a725-595ee7bd9782",
   "metadata": {},
   "source": [
    "The attention scores for _ship:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9f5c93cd-f8dd-4611-bee7-98eec7e69438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(11,), dtype=float32, numpy=\n",
       "array([0.03030742, 0.03024589, 0.02764813, 0.04066233, 0.04593488,\n",
       "       0.03426558, 0.55297625, 0.02968703, 0.04593488, 0.03426558,\n",
       "       0.12807208], dtype=float32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_layer(np.array([embeddings_seq]), \n",
    "          np.array([embeddings_seq]),\n",
    "          np.array([embeddings_seq]),\n",
    "         return_attention_scores=True)[1][0][0][6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e926183c-0734-49c7-9480-190f6c892adf",
   "metadata": {},
   "source": [
    "The attention vector for _ship:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1be2d12f-9e76-4f53-baea-8178dd5a7e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=float32, numpy=\n",
       "array([ 1.0387306 ,  0.10328995,  0.34260815, -0.43199396,  0.22365318,\n",
       "       -0.09583741, -0.99261564,  0.6661626 ,  0.44239208, -0.79419196,\n",
       "        0.56381553,  0.9921032 ,  0.02053553,  0.5082416 ,  0.07430474,\n",
       "       -0.17727737, -0.34077048,  0.56745   , -1.1545366 , -0.5717591 ,\n",
       "        0.42881253,  0.41905236, -0.06575862, -0.3338547 ,  0.6682152 ,\n",
       "       -1.7473364 , -0.04854015,  0.15311077,  0.8642304 , -0.1447473 ,\n",
       "        2.6571252 , -0.05447169, -0.5343237 ,  0.31597912,  0.40407795,\n",
       "        0.22768481,  0.39576727, -0.29159355, -0.11262506, -0.13846776,\n",
       "        0.17435764, -0.5375053 ,  0.9498529 , -0.41448146, -0.10386168,\n",
       "       -0.17551401, -0.22132863, -0.3994514 ,  0.21188116, -0.36097592],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_layer(np.array([embeddings_seq]), \n",
    "          np.array([embeddings_seq]),\n",
    "          np.array([embeddings_seq]),\n",
    "         return_attention_scores=True)[0][0][6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ad8d94-0a2d-4e16-ad54-151f2e9facad",
   "metadata": {},
   "source": [
    "## Test with a simple matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25eda3f0-52b7-4c03-9167-7e331a018853",
   "metadata": {},
   "source": [
    "Three words, dimension of embeddings: 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2663ebcb-8e4b-4720-9ed3-c88a950dc214",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_sequence = np.array([[[1.0, 0.0, 0.0, 1.0],\n",
    "                                 [0.0, 1.5, 1.0, 1.0],\n",
    "                                 [0.0, 1.0, 1.0, 1.0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "946d88eb-7522-476b-80d4-ceac7af6a2e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 4)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input_sequence.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab40159-3c6a-45b7-87c4-3fa6f52186a3",
   "metadata": {},
   "source": [
    "### Self-attention from the book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5bca6930-4deb-456b-8ac7-7bc92d77f51b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.45186276, 0.68517155, 0.54813724, 1.        ],\n",
       "        [0.10450673, 1.16085775, 0.89549327, 1.        ],\n",
       "        [0.13872271, 1.10337221, 0.86127729, 1.        ]]),\n",
       " array([[0.45186276, 0.27406862, 0.27406862],\n",
       "        [0.10450673, 0.53072895, 0.36476432],\n",
       "        [0.13872271, 0.48418985, 0.37708743]]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_attention(test_input_sequence[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cdbf2f-dc0a-4354-bf96-30b99cddee20",
   "metadata": {},
   "source": [
    "### Multihead attention from Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "527fc0db-4fd9-413e-9634-a54469adb4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "att_layer = MultiHeadAttention(num_heads=1, \n",
    "                               key_dim=4, \n",
    "                               #kernel_initializer=tf.keras.initializers.ones(), #my_init,\n",
    "                               use_bias=False, attention_axes=(1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0909144a-4c17-45de-82f1-3cb8547eb985",
   "metadata": {},
   "source": [
    "The multihead attention uses a Glorot initialization of the dense layers. The results will be different for those of `self_attention()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ffd9a3b5-4645-4fa5-8d84-06cc6dd72822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 3, 4), dtype=float32, numpy=\n",
       " array([[[-0.3766441 ,  0.33481684, -0.01428649,  0.14875287],\n",
       "         [-0.37168398,  0.3519954 ,  0.00520262,  0.16505039],\n",
       "         [-0.37213954,  0.34879547,  0.00183475,  0.16199642]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 1, 3, 3), dtype=float32, numpy=\n",
       " array([[[[0.3819979 , 0.30329558, 0.31470647],\n",
       "          [0.28096676, 0.35826197, 0.3607713 ],\n",
       "          [0.29804945, 0.34727123, 0.3546793 ]]]], dtype=float32)>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_layer(test_input_sequence, \n",
    "          test_input_sequence,\n",
    "          test_input_sequence,\n",
    "         return_attention_scores=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901e889b-a828-40cc-b208-c6688be25c14",
   "metadata": {},
   "source": [
    "Weights of the dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8b597eee-fee4-4a15-9aaf-d62e7e9c1b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'multi_head_attention_1/query/kernel:0' shape=(4, 1, 4) dtype=float32, numpy=\n",
       " array([[[ 0.26624137, -0.12857488,  0.21427745,  0.12562203]],\n",
       " \n",
       "        [[ 0.07248586, -0.01270992, -0.3568948 , -0.03817797]],\n",
       " \n",
       "        [[-0.5223397 ,  0.29709953,  0.06554359,  0.5066794 ]],\n",
       " \n",
       "        [[-0.33860448,  0.0512777 ,  0.01473051, -0.35103783]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'multi_head_attention_1/key/kernel:0' shape=(4, 1, 4) dtype=float32, numpy=\n",
       " array([[[ 0.40734494, -0.26249927,  0.1891346 , -0.33850628]],\n",
       " \n",
       "        [[ 0.3839069 ,  0.38551158, -0.26628643,  0.12939876]],\n",
       " \n",
       "        [[ 0.29185414,  0.13014114, -0.4210621 ,  0.00790733]],\n",
       " \n",
       "        [[ 0.26130402, -0.13597435,  0.5441804 ,  0.21766269]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'multi_head_attention_1/value/kernel:0' shape=(4, 1, 4) dtype=float32, numpy=\n",
       " array([[[-0.4021383 , -0.25917742, -0.2872401 , -0.16896671]],\n",
       " \n",
       "        [[-0.1219289 ,  0.46332443,  0.423333  , -0.54266614]],\n",
       " \n",
       "        [[ 0.22427511,  0.44424736,  0.00114197,  0.33117718]],\n",
       " \n",
       "        [[ 0.14903271, -0.23351702,  0.37479633, -0.24955574]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'multi_head_attention_1/attention_output/kernel:0' shape=(1, 4, 4) dtype=float32, numpy=\n",
       " array([[[ 0.4771592 , -0.30209643,  0.43288654, -0.18476617],\n",
       "         [ 0.00802469,  0.02085537,  0.33232528,  0.44002837],\n",
       "         [-0.06931663,  0.2649575 , -0.6414784 , -0.53695893],\n",
       "         [ 0.6776833 , -0.34904242, -0.47159925, -0.6496675 ]]],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_layer.weights #att_layer.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed433e0c-ebad-4319-926c-8d67af07af67",
   "metadata": {},
   "source": [
    "### By-passing the dense layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83941332-2d50-431f-ad4a-3e5e9b0722e7",
   "metadata": {},
   "source": [
    "We use weights of identity matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "238ed967-fc32-476f-a258-8031fb2b57cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_4 = np.identity(4)\n",
    "w_pt_4 = [i_4.reshape(4, 1, 4) for _ in range(3)] + [i_4.reshape(1, 4, 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2ebcab2b-c158-41e9-9d5e-4aed62d74416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[1., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 1., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 1., 0.]],\n",
       " \n",
       "        [[0., 0., 0., 1.]]]),\n",
       " array([[[1., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 1., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 1., 0.]],\n",
       " \n",
       "        [[0., 0., 0., 1.]]]),\n",
       " array([[[1., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 1., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 1., 0.]],\n",
       " \n",
       "        [[0., 0., 0., 1.]]]),\n",
       " array([[[1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 0., 1., 0.],\n",
       "         [0., 0., 0., 1.]]])]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_pt_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa12ec3-7044-4440-abdc-e6786dd078eb",
   "metadata": {},
   "source": [
    "We set these weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "42b0789a-e4c6-4198-ab99-b74fbbc3d39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "att_layer.set_weights(w_pt_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8892df4-4e1e-4c02-9d00-04be89fc41fd",
   "metadata": {},
   "source": [
    "Now we have the same results as with `self_attention()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "67d2d604-eb6e-43e4-b51a-2d645f5eb227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 3, 4), dtype=float32, numpy=\n",
       " array([[[0.45186275, 0.6851716 , 0.54813725, 1.        ],\n",
       "         [0.10450672, 1.1608577 , 0.89549327, 1.        ],\n",
       "         [0.13872272, 1.1033722 , 0.86127734, 1.        ]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 1, 3, 3), dtype=float32, numpy=\n",
       " array([[[[0.45186275, 0.27406862, 0.27406862],\n",
       "          [0.10450672, 0.53072894, 0.3647643 ],\n",
       "          [0.13872272, 0.48418987, 0.37708744]]]], dtype=float32)>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_layer(test_input_sequence, \n",
    "          test_input_sequence,\n",
    "          test_input_sequence,\n",
    "         return_attention_scores=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
