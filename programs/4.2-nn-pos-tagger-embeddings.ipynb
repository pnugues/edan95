{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-of-Speech Tagging using Feedforward Networks and Embeddings\n",
    "Author: Pierre Nugues\n",
    "\n",
    "A part-of-speech tagger using feed-forward networks and GloVe embeddings and trained on a corpus following the Universal Dependencies format. Here we use the English Web Treebank:\n",
    "https://github.com/UniversalDependencies/UD_English-EWT/tree/master."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import time\n",
    "from keras import models\n",
    "from keras.layers import LSTM, Bidirectional, SimpleRNN, Dense, Embedding, Flatten\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.models import load_model\n",
    "import math\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMIZER = 'rmsprop'\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 8\n",
    "MINI_CORPUS = False\n",
    "EMBEDDING_DIM = 100\n",
    "W_SIZE = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Embeddings\n",
    "We will use GloVe embeddings and load them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(file):\n",
    "    \"\"\"\n",
    "    Return the embeddings in the from of a dictionary\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    file = file\n",
    "    embeddings = {}\n",
    "    glove = open(file)\n",
    "    for line in glove:\n",
    "        values = line.strip().split()\n",
    "        word = values[0]\n",
    "        vector = np.array(values[1:])\n",
    "        embeddings[word] = vector\n",
    "    glove.close()\n",
    "    embeddings_dict = embeddings\n",
    "    embedded_words = sorted(list(embeddings_dict.keys()))\n",
    "    return embeddings_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_file = '/Users/pierre/Documents/Cours/EDAN20/corpus/glove.6B.100d.txt'\n",
    "embeddings_dict = load(embedding_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['-0.61454', '0.89693', '0.56771', '0.39102', '-0.22437', '0.49035',\n",
       "       '0.10868', '0.27411', '-0.23833', '-0.52153', '0.73551',\n",
       "       '-0.32654', '0.51304', '0.32415', '-0.46709', '0.68051',\n",
       "       '-0.25497', '-0.040484', '-0.54418', '-1.0548', '-0.46692',\n",
       "       '0.23557', '0.31234', '-0.34537', '0.14793', '-0.53745',\n",
       "       '-0.43215', '-0.48724', '-0.51019', '-0.9051', '-0.17919',\n",
       "       '-0.018376', '0.09719', '-0.31623', '0.7512', '0.92236',\n",
       "       '-0.49965', '0.14036', '-0.28296', '-0.97443', '-0.0094408',\n",
       "       '-0.62944', '0.14711', '-0.94376', '0.0075222', '0.18565',\n",
       "       '-0.99172', '0.072789', '-0.18474', '-0.52901', '0.38995',\n",
       "       '-0.45677', '-0.21932', '1.3723', '-0.29636', '-2.2342',\n",
       "       '-0.36667', '0.04987', '0.63421', '0.53275', '-0.53955', '0.31398',\n",
       "       '-0.44698', '-0.38389', '0.066668', '-0.02168', '0.20558',\n",
       "       '0.59456', '-0.24892', '-0.52795', '-0.3761', '0.077104',\n",
       "       '0.75222', '-0.2647', '-0.0587', '0.67541', '-0.16559', '-0.49278',\n",
       "       '-0.26327', '-0.21215', '0.24317', '0.17006', '-0.2926', '-0.5009',\n",
       "       '-0.56638', '-0.40377', '-0.48452', '-0.32539', '0.75293',\n",
       "       '0.0049585', '-0.32115', '0.28899', '-0.042392', '0.63863',\n",
       "       '-0.20332', '-0.46785', '-0.15661', '0.2179', '1.4143', '0.40034'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dict['table']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# newdoc id = weblog-juancole.com_juancole_20051126063000_ENG_20051126_063000\\n# sent_id = weblog-jua'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_ud_en_ewt():\n",
    "    BASE_DIR = '/Users/pierre/Documents/Cours/EDAN20/corpus/ud-treebanks-v2.8/UD_English-EWT/'\n",
    "    train_file = BASE_DIR + 'en_ewt-ud-train.conllu'\n",
    "    dev_file = BASE_DIR + 'en_ewt-ud-dev.conllu'\n",
    "    test_file = BASE_DIR + 'en_ewt-ud-test.conllu'\n",
    "    column_names = ['ID', 'FORM', 'LEMMA', 'UPOS', 'XPOS', \n",
    "                    'FEATS', 'HEAD', 'DEPREL', 'HEAD', 'DEPS', 'MISC']\n",
    "    column_names = list(map(str.lower, column_names))\n",
    "    train_sentences = open(train_file).read().strip()\n",
    "    dev_sentences = open(dev_file).read().strip()\n",
    "    test_sentences = open(test_file).read().strip()\n",
    "    # test2_sentences = open(test2_file).read().strip()\n",
    "    return train_sentences, dev_sentences, test_sentences, column_names\n",
    "\n",
    "def load_conll2009_pos():\n",
    "    BASE_DIR = '/Users/pierre/Documents/Cours/EDAN20/corpus/conll2009/en/'\n",
    "    train_file = BASE_DIR + 'CoNLL2009-ST-English-train-pos.txt'\n",
    "    dev_file = BASE_DIR + 'CoNLL2009-ST-English-development-pos.txt'\n",
    "    test_file = BASE_DIR + 'CoNLL2009-ST-test-words-pos.txt'\n",
    "    # test2_file = 'simple_pos_test.txt'\n",
    "\n",
    "    column_names = ['id', 'form', 'lemma', 'plemma', 'pos', 'ppos']\n",
    "\n",
    "    train_sentences = open(train_file).read().strip()\n",
    "    dev_sentences = open(dev_file).read().strip()\n",
    "    test_sentences = open(test_file).read().strip()\n",
    "    # test2_sentences = open(test2_file).read().strip()\n",
    "    return train_sentences, dev_sentences, test_sentences, column_names\n",
    "\n",
    "# train_sentences, dev_sentences, test_sentences, column_names = \\\n",
    "# load_conll2009_pos()\n",
    "train_sentences, dev_sentences, test_sentences, column_names =\\\n",
    "load_ud_en_ewt()\n",
    "train_sentences[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the Corpus in a Dictionary\n",
    "We follow the fit-transform pattern of sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "\n",
    "class Token(dict):\n",
    "    pass\n",
    "\n",
    "class CoNLLDictorizer:\n",
    "\n",
    "    def __init__(self, column_names, sent_sep='\\n\\n', col_sep=' +'):\n",
    "        self.column_names = column_names\n",
    "        self.sent_sep = sent_sep\n",
    "        self.col_sep = col_sep\n",
    "\n",
    "    def fit(self):\n",
    "        pass\n",
    "\n",
    "    def transform(self, corpus):\n",
    "        corpus = corpus.strip()\n",
    "        sentences = re.split(self.sent_sep, corpus)\n",
    "        return list(map(self._split_in_words, sentences))\n",
    "\n",
    "    def fit_transform(self, corpus):\n",
    "        return self.transform(corpus)\n",
    "\n",
    "    def _split_in_words(self, sentence):\n",
    "        rows = re.split('\\n', sentence)\n",
    "        rows = [row for row in rows if row[0] != '#']\n",
    "        return [Token(dict(zip(self.column_names,\n",
    "                               re.split(self.col_sep, row))))\n",
    "                for row in rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First sentence, train: [{'id': '1', 'form': 'Al', 'lemma': 'Al', 'upos': 'PROPN', 'xpos': 'NNP', 'feats': 'Number=Sing', 'head': '0:root', 'deprel': 'root', 'deps': 'SpaceAfter=No'}, {'id': '2', 'form': '-', 'lemma': '-', 'upos': 'PUNCT', 'xpos': 'HYPH', 'feats': '_', 'head': '1:punct', 'deprel': 'punct', 'deps': 'SpaceAfter=No'}, {'id': '3', 'form': 'Zaman', 'lemma': 'Zaman', 'upos': 'PROPN', 'xpos': 'NNP', 'feats': 'Number=Sing', 'head': '1:flat', 'deprel': 'flat', 'deps': '_'}, {'id': '4', 'form': ':', 'lemma': ':', 'upos': 'PUNCT', 'xpos': ':', 'feats': '_', 'head': '1:punct', 'deprel': 'punct', 'deps': '_'}, {'id': '5', 'form': 'American', 'lemma': 'American', 'upos': 'ADJ', 'xpos': 'JJ', 'feats': 'Degree=Pos', 'head': '6:amod', 'deprel': 'amod', 'deps': '_'}, {'id': '6', 'form': 'forces', 'lemma': 'force', 'upos': 'NOUN', 'xpos': 'NNS', 'feats': 'Number=Plur', 'head': '7:nsubj', 'deprel': 'nsubj', 'deps': '_'}, {'id': '7', 'form': 'killed', 'lemma': 'kill', 'upos': 'VERB', 'xpos': 'VBD', 'feats': 'Mood=Ind|Tense=Past|VerbForm=Fin', 'head': '1:parataxis', 'deprel': 'parataxis', 'deps': '_'}, {'id': '8', 'form': 'Shaikh', 'lemma': 'Shaikh', 'upos': 'PROPN', 'xpos': 'NNP', 'feats': 'Number=Sing', 'head': '7:obj', 'deprel': 'obj', 'deps': '_'}, {'id': '9', 'form': 'Abdullah', 'lemma': 'Abdullah', 'upos': 'PROPN', 'xpos': 'NNP', 'feats': 'Number=Sing', 'head': '8:flat', 'deprel': 'flat', 'deps': '_'}, {'id': '10', 'form': 'al', 'lemma': 'al', 'upos': 'PROPN', 'xpos': 'NNP', 'feats': 'Number=Sing', 'head': '8:flat', 'deprel': 'flat', 'deps': 'SpaceAfter=No'}, {'id': '11', 'form': '-', 'lemma': '-', 'upos': 'PUNCT', 'xpos': 'HYPH', 'feats': '_', 'head': '8:punct', 'deprel': 'punct', 'deps': 'SpaceAfter=No'}, {'id': '12', 'form': 'Ani', 'lemma': 'Ani', 'upos': 'PROPN', 'xpos': 'NNP', 'feats': 'Number=Sing', 'head': '8:flat', 'deprel': 'flat', 'deps': 'SpaceAfter=No'}, {'id': '13', 'form': ',', 'lemma': ',', 'upos': 'PUNCT', 'xpos': ',', 'feats': '_', 'head': '8:punct', 'deprel': 'punct', 'deps': '_'}, {'id': '14', 'form': 'the', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'feats': 'Definite=Def|PronType=Art', 'head': '15:det', 'deprel': 'det', 'deps': '_'}, {'id': '15', 'form': 'preacher', 'lemma': 'preacher', 'upos': 'NOUN', 'xpos': 'NN', 'feats': 'Number=Sing', 'head': '8:appos', 'deprel': 'appos', 'deps': '_'}, {'id': '16', 'form': 'at', 'lemma': 'at', 'upos': 'ADP', 'xpos': 'IN', 'feats': '_', 'head': '18:case', 'deprel': 'case', 'deps': '_'}, {'id': '17', 'form': 'the', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'feats': 'Definite=Def|PronType=Art', 'head': '18:det', 'deprel': 'det', 'deps': '_'}, {'id': '18', 'form': 'mosque', 'lemma': 'mosque', 'upos': 'NOUN', 'xpos': 'NN', 'feats': 'Number=Sing', 'head': '7:obl:at', 'deprel': 'obl', 'deps': '_'}, {'id': '19', 'form': 'in', 'lemma': 'in', 'upos': 'ADP', 'xpos': 'IN', 'feats': '_', 'head': '21:case', 'deprel': 'case', 'deps': '_'}, {'id': '20', 'form': 'the', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'feats': 'Definite=Def|PronType=Art', 'head': '21:det', 'deprel': 'det', 'deps': '_'}, {'id': '21', 'form': 'town', 'lemma': 'town', 'upos': 'NOUN', 'xpos': 'NN', 'feats': 'Number=Sing', 'head': '18:nmod:in', 'deprel': 'nmod', 'deps': '_'}, {'id': '22', 'form': 'of', 'lemma': 'of', 'upos': 'ADP', 'xpos': 'IN', 'feats': '_', 'head': '23:case', 'deprel': 'case', 'deps': '_'}, {'id': '23', 'form': 'Qaim', 'lemma': 'Qaim', 'upos': 'PROPN', 'xpos': 'NNP', 'feats': 'Number=Sing', 'head': '21:nmod:of', 'deprel': 'nmod', 'deps': 'SpaceAfter=No'}, {'id': '24', 'form': ',', 'lemma': ',', 'upos': 'PUNCT', 'xpos': ',', 'feats': '_', 'head': '21:punct', 'deprel': 'punct', 'deps': '_'}, {'id': '25', 'form': 'near', 'lemma': 'near', 'upos': 'ADP', 'xpos': 'IN', 'feats': '_', 'head': '28:case', 'deprel': 'case', 'deps': '_'}, {'id': '26', 'form': 'the', 'lemma': 'the', 'upos': 'DET', 'xpos': 'DT', 'feats': 'Definite=Def|PronType=Art', 'head': '28:det', 'deprel': 'det', 'deps': '_'}, {'id': '27', 'form': 'Syrian', 'lemma': 'Syrian', 'upos': 'ADJ', 'xpos': 'JJ', 'feats': 'Degree=Pos', 'head': '28:amod', 'deprel': 'amod', 'deps': '_'}, {'id': '28', 'form': 'border', 'lemma': 'border', 'upos': 'NOUN', 'xpos': 'NN', 'feats': 'Number=Sing', 'head': '21:nmod:near', 'deprel': 'nmod', 'deps': 'SpaceAfter=No'}, {'id': '29', 'form': '.', 'lemma': '.', 'upos': 'PUNCT', 'xpos': '.', 'feats': '_', 'head': '1:punct', 'deprel': 'punct', 'deps': '_'}]\n"
     ]
    }
   ],
   "source": [
    "conll_dict = CoNLLDictorizer(column_names, col_sep='\\t')\n",
    "\n",
    "train_dict = conll_dict.transform(train_sentences)\n",
    "dev_dict = conll_dict.transform(dev_sentences)\n",
    "test_dict = conll_dict.transform(test_sentences)\n",
    "\n",
    "if MINI_CORPUS:\n",
    "    train_dict = train_dict[:len(train_dict) // 5]\n",
    "print('First sentence, train:', train_dict[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the Context and Dictorizing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextDictorizer():\n",
    "    \"\"\"\n",
    "    Extract contexts of words in a sequence\n",
    "    Contexts are of w_size to the left and to the right\n",
    "    Builds an X matrix in the form of a dictionary\n",
    "    and possibly extracts the output, y, if not in the test step\n",
    "    If the test_step is True, returns y = []\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input='form', output='upos', w_size=2, tolower=True):\n",
    "        self.BOS_symbol = '__BOS__'\n",
    "        self.EOS_symbol = '__EOS__'\n",
    "        self.input = input\n",
    "        self.output = output\n",
    "        self.w_size = w_size\n",
    "        self.tolower = tolower\n",
    "        # This was not correct as the names were not sorted\n",
    "        # self.feature_names = [input + '_' + str(i)\n",
    "        #                     for i in range(-w_size, w_size + 1)]\n",
    "        # To be sure the names are ordered\n",
    "        zeros = math.ceil(math.log10(2 * w_size + 1))\n",
    "        self.feature_names = [input + '_' + str(i).zfill(zeros) for \n",
    "                              i in range(2 * w_size + 1)]\n",
    "\n",
    "    def fit(self, sentences):\n",
    "        \"\"\"\n",
    "        Build the padding rows\n",
    "        :param sentences:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.column_names = sentences[0][0].keys()\n",
    "        start = [self.BOS_symbol] * len(self.column_names)\n",
    "        end = [self.EOS_symbol] * len(self.column_names)\n",
    "        start_token = Token(dict(zip(self.column_names, start)))\n",
    "        end_token = Token(dict(zip(self.column_names, end)))\n",
    "        self.start_rows = [start_token] * self.w_size\n",
    "        self.end_rows = [end_token] * self.w_size\n",
    "\n",
    "    def transform(self, sentences, training_step=True):\n",
    "        X_corpus = []\n",
    "        y_corpus = []\n",
    "        for sentence in sentences:\n",
    "            X, y = self._transform_sentence(sentence, training_step)\n",
    "            X_corpus += X\n",
    "            if training_step:\n",
    "                y_corpus += y\n",
    "        return X_corpus, y_corpus\n",
    "\n",
    "    def fit_transform(self, sentences):\n",
    "        self.fit(sentences)\n",
    "        return self.transform(sentences)\n",
    "\n",
    "    def _transform_sentence(self, sentence, training_step=True):\n",
    "        # We extract y\n",
    "        if training_step:\n",
    "            y = [row[self.output] for row in sentence]\n",
    "        else:\n",
    "            y = None\n",
    "\n",
    "        # We pad the sentence\n",
    "        sentence = self.start_rows + sentence + self.end_rows\n",
    "\n",
    "        # We extract the features\n",
    "        X = list()\n",
    "        for i in range(len(sentence) - 2 * self.w_size):\n",
    "            # x is a row of X\n",
    "            x = list()\n",
    "            # The words in lower case\n",
    "            for j in range(2 * self.w_size + 1):\n",
    "                if self.tolower:\n",
    "                    x.append(sentence[i + j][self.input].lower())\n",
    "                else:\n",
    "                    x.append(sentence[i + j][self.input])\n",
    "            # We represent the feature vector as a dictionary\n",
    "            X.append(dict(zip(self.feature_names, x)))\n",
    "        return X, y\n",
    "\n",
    "    def print_example(self, sentences, id=1968):\n",
    "        \"\"\"\n",
    "        :param corpus:\n",
    "        :param id:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # We print the features to check they match Table 8.1 in my book (second edition)\n",
    "        # We use the training step extraction with the dynamic features\n",
    "        Xs, ys = self._transform_sentence(sentences[id])\n",
    "        print('X for sentence #', id, Xs)\n",
    "        print('y for sentence #', id, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_dictorizer = ContextDictorizer()\n",
    "context_dictorizer.fit(train_dict)\n",
    "X_train_dict, y_train_cat = context_dictorizer.transform(train_dict)\n",
    "X_val_dict, y_val_cat = context_dictorizer.transform(dev_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X for sentence # 1968 [{'form_0': '__bos__', 'form_1': '__bos__', 'form_2': 'do', 'form_3': 'we', 'form_4': 'intend'}, {'form_0': '__bos__', 'form_1': 'do', 'form_2': 'we', 'form_3': 'intend', 'form_4': 'to'}, {'form_0': 'do', 'form_1': 'we', 'form_2': 'intend', 'form_3': 'to', 'form_4': 'reference'}, {'form_0': 'we', 'form_1': 'intend', 'form_2': 'to', 'form_3': 'reference', 'form_4': 'a'}, {'form_0': 'intend', 'form_1': 'to', 'form_2': 'reference', 'form_3': 'a', 'form_4': 'particular'}, {'form_0': 'to', 'form_1': 'reference', 'form_2': 'a', 'form_3': 'particular', 'form_4': 'manufacturer'}, {'form_0': 'reference', 'form_1': 'a', 'form_2': 'particular', 'form_3': 'manufacturer', 'form_4': ','}, {'form_0': 'a', 'form_1': 'particular', 'form_2': 'manufacturer', 'form_3': ',', 'form_4': 'or'}, {'form_0': 'particular', 'form_1': 'manufacturer', 'form_2': ',', 'form_3': 'or', 'form_4': 'should'}, {'form_0': 'manufacturer', 'form_1': ',', 'form_2': 'or', 'form_3': 'should', 'form_4': 'this'}, {'form_0': ',', 'form_1': 'or', 'form_2': 'should', 'form_3': 'this', 'form_4': 'be'}, {'form_0': 'or', 'form_1': 'should', 'form_2': 'this', 'form_3': 'be', 'form_4': 'more'}, {'form_0': 'should', 'form_1': 'this', 'form_2': 'be', 'form_3': 'more', 'form_4': 'generic'}, {'form_0': 'this', 'form_1': 'be', 'form_2': 'more', 'form_3': 'generic', 'form_4': '?'}, {'form_0': 'be', 'form_1': 'more', 'form_2': 'generic', 'form_3': '?', 'form_4': '__eos__'}, {'form_0': 'more', 'form_1': 'generic', 'form_2': '?', 'form_3': '__eos__', 'form_4': '__eos__'}]\n",
      "y for sentence # 1968 ['AUX', 'PRON', 'VERB', 'PART', 'VERB', 'DET', 'ADJ', 'NOUN', 'PUNCT', 'CCONJ', 'AUX', 'PRON', 'AUX', 'ADV', 'ADJ', 'PUNCT']\n"
     ]
    }
   ],
   "source": [
    "context_dictorizer.print_example(train_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We extract all the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# unique words seen in training corpus: 17113\n"
     ]
    }
   ],
   "source": [
    "corpus_words = []\n",
    "for x in X_train_dict:\n",
    "    corpus_words.extend(x.values())\n",
    "corpus_words = sorted(set(corpus_words))\n",
    "print('# unique words seen in training corpus:', len(corpus_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We add these words to the vocabulary\n",
    "We add one word to the count for the unknown words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words in GloVe: 400000\n",
      "# unique words in the vocabulary: embeddings and corpus: 402010\n"
     ]
    }
   ],
   "source": [
    "embeddings_words = embeddings_dict.keys()\n",
    "print('Words in GloVe:',  len(embeddings_dict.keys()))\n",
    "vocabulary_words = set(corpus_words + list(embeddings_words))\n",
    "cnt_uniq = len(vocabulary_words) + 1\n",
    "print('# unique words in the vocabulary: embeddings and corpus:', \n",
    "      cnt_uniq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We now build an index\n",
    "We keep index 0 for the unknown words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_word = dict(enumerate(sorted(vocabulary_words), start=1))\n",
    "word_idx = {v: k for k, v in idx_word.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We replace the words with their index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for x_train_dict in X_train_dict:\n",
    "    for word in x_train_dict:\n",
    "        x_train_dict[word] = word_idx[x_train_dict[word]]\n",
    "\n",
    "for x_val_dict in X_val_dict:\n",
    "    for word in x_val_dict:\n",
    "        x_val_dict[word] = word_idx.get(x_val_dict[word], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_vect = DictVectorizer(sparse=False)\n",
    "X_train = dict_vect.fit_transform(X_train_dict)\n",
    "X_val = dict_vect.transform(X_val_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207224, 5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 43516.,  43516.,  50470.,    653., 397775.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And $\\mathbf{y}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The POS and the number of different POS\n",
    "pos_list = sorted(list(set(y_train_cat)))\n",
    "NB_CLASSES = len(pos_list) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We build a part-of-speech index. We keep 0 for unknown symbols in the test set\n",
    "idx_pos = dict(enumerate(pos_list, start=1))\n",
    "pos_idx = {v: k for k, v in idx_pos.items()}\n",
    "\n",
    "# We encode y\n",
    "y_train = np.array([pos_idx[i] for i in y_train_cat])\n",
    "y_val = np.array([pos_idx[i] for i in y_val_cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PROPN',\n",
       " 'PUNCT',\n",
       " 'PROPN',\n",
       " 'PUNCT',\n",
       " 'ADJ',\n",
       " 'NOUN',\n",
       " 'VERB',\n",
       " 'PROPN',\n",
       " 'PROPN',\n",
       " 'PROPN']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_cat[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 13, 12, 13,  1,  8, 16, 12, 12, 12])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We now create the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.random.random((len(vocabulary_words) + 1, \n",
    "                                     EMBEDDING_DIM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in vocabulary_words:\n",
    "    if word in embeddings_dict:\n",
    "        # If the words are in the embeddings, we fill them with a value\n",
    "        embedding_matrix[word_idx[word]] = embeddings_dict[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-19 13:23:32.453891: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import initializers\n",
    "\n",
    "model = models.Sequential([\n",
    "    Embedding(cnt_uniq, \n",
    "              EMBEDDING_DIM,\n",
    "              trainable=True,\n",
    "              embeddings_initializer=initializers.Constant(embedding_matrix),\n",
    "              input_length=2 * W_SIZE + 1),\n",
    "    Flatten(),\n",
    "    Dense(NB_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "#model.layers[0].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=OPTIMIZER,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 5, 100)            40201000  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 500)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 19)                9519      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,210,519\n",
      "Trainable params: 40,210,519\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a callback to store our best model using the validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint('simple_embeddings.keras',\n",
    "                                   save_best_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "1619/1619 [==============================] - 214s 132ms/step - loss: 0.5388 - accuracy: 0.8430 - val_loss: 0.3254 - val_accuracy: 0.9010\n",
      "Epoch 2/8\n",
      "1619/1619 [==============================] - 216s 134ms/step - loss: 0.2287 - accuracy: 0.9290 - val_loss: 0.2739 - val_accuracy: 0.9172\n",
      "Epoch 3/8\n",
      "1619/1619 [==============================] - 218s 135ms/step - loss: 0.1836 - accuracy: 0.9430 - val_loss: 0.2632 - val_accuracy: 0.9215\n",
      "Epoch 4/8\n",
      "1619/1619 [==============================] - 219s 135ms/step - loss: 0.1604 - accuracy: 0.9505 - val_loss: 0.2566 - val_accuracy: 0.9243\n",
      "Epoch 5/8\n",
      "1619/1619 [==============================] - 221s 137ms/step - loss: 0.1444 - accuracy: 0.9559 - val_loss: 0.2538 - val_accuracy: 0.9230\n",
      "Epoch 6/8\n",
      "1619/1619 [==============================] - 223s 138ms/step - loss: 0.1323 - accuracy: 0.9599 - val_loss: 0.2533 - val_accuracy: 0.9246\n",
      "Epoch 7/8\n",
      "1619/1619 [==============================] - 221s 136ms/step - loss: 0.1222 - accuracy: 0.9633 - val_loss: 0.2531 - val_accuracy: 0.9230\n",
      "Epoch 8/8\n",
      "1619/1619 [==============================] - 205s 127ms/step - loss: 0.1138 - accuracy: 0.9658 - val_loss: 0.2572 - val_accuracy: 0.9235\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=EPOCHS, \n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=(X_val, y_val), \n",
    "                    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load our best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('simple_embeddings.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "796/796 [==============================] - 1s 683us/step - loss: 0.2433 - accuracy: 0.9261\n",
      "Optimizer rmsprop Epochs 8 Batch size 128 Mini corpus False\n",
      "Loss: 0.24327071011066437\n",
      "Accuracy: 0.9261049032211304\n"
     ]
    }
   ],
   "source": [
    "X_test_dict, y_test_cat = context_dictorizer.transform(test_dict)\n",
    "for x_test_dict in X_test_dict:\n",
    "    for word in x_test_dict:\n",
    "        x_test_dict[word] = word_idx.get(x_test_dict[word], 0)\n",
    "            \n",
    "# We transform the symbols into numbers\n",
    "X_test = dict_vect.transform(X_test_dict)\n",
    "y_test = np.array([pos_idx.get(i, 0) for i in y_test_cat])\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Optimizer', OPTIMIZER, 'Epochs', EPOCHS, 'Batch size', \n",
    "      BATCH_SIZE, 'Mini corpus', MINI_CORPUS)\n",
    "print('Loss:', test_loss)\n",
    "print('Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About 92.29 for a simple logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction of parts of speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentence(sentence, dict_vect, model, word_idx, idx_pos):\n",
    "    column_names = ['id', 'form']\n",
    "    sentence = list(enumerate(sentence.lower().split(), start=1))\n",
    "    conll_cols = ''\n",
    "    for tuple in sentence:\n",
    "        conll_cols += str(tuple[0]) + '\\t' + tuple[1] + '\\n'\n",
    "    # print(conll_cols)\n",
    "\n",
    "    conll_dict = CoNLLDictorizer(column_names, col_sep='\\t')\n",
    "    sent_dict = conll_dict.transform(conll_cols)\n",
    "    # print('Sentence:', sent_dict[0])\n",
    "\n",
    "    context_dictorizer = ContextDictorizer()\n",
    "    context_dictorizer.fit(sent_dict)\n",
    "    X_dict, y = context_dictorizer.transform(sent_dict, \n",
    "                                             training_step=False)\n",
    "    # print('Sentence, padded:', X_dict)\n",
    "    # print('POS, y:', y)\n",
    "\n",
    "    for x_dict in X_dict:\n",
    "        for word in x_dict:\n",
    "            x_dict[word] = word_idx.get(x_dict[word], 1)\n",
    "    X = dict_vect.transform(X_dict)\n",
    "\n",
    "    # print(X)\n",
    "    y_prob = model.predict(X)\n",
    "    y_pred = y_prob.argmax(axis=-1)\n",
    "    y_pred_cat = list(map(idx_pos.get, y_pred))\n",
    "    return y_pred_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That round table might collapse .\n",
      "['DET', 'NOUN', 'NOUN', 'AUX', 'VERB', 'PUNCT']\n",
      "The man can learn well .\n",
      "['DET', 'NOUN', 'AUX', 'VERB', 'ADV', 'PUNCT']\n",
      "The man can swim .\n",
      "['DET', 'NOUN', 'AUX', 'VERB', 'PUNCT']\n",
      "The man can simwo .\n",
      "['DET', 'NOUN', 'AUX', 'PUNCT', 'PUNCT']\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"That round table might collapse .\",\n",
    "                 \"The man can learn well .\",\n",
    "                 \"The man can swim .\",\n",
    "                 \"The man can simwo .\"]\n",
    "for sentence in sentences:\n",
    "    y_test_cat_pred = predict_sentence(sentence.lower(), \n",
    "                                       dict_vect,\n",
    "                                       model, word_idx, \n",
    "                                       idx_pos)\n",
    "    print(sentence)\n",
    "    print(y_test_cat_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
